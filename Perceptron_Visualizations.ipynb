{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Learning Algorithm, Supervised learning method: \n",
    "### A break-down of Rosenblatt's simple, crude Perceptron in python,  with visualizations in matplotlib and Bokeh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Resources: A Simple Learning Model by Abu-Mostafa, Magdon-Ismail, Lin, Ch. 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "%matplotlib\n",
    "# to view graphing inside the cell use ''%matplotlib inline' instead of ''%matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This 'χ' stores multiple records as a matrix for the machine to learn from.  \n",
    "# Each row of the matrix is a piece of data, a record, an observation, event, etc.\n",
    "# First column are all 1's for multiplying with the bias weights\n",
    "# Second column contains feature 1 (x1) of each record\n",
    "# Third column contains feature 2 (x2) of each record\n",
    "# χ = {1} x ℝ^2 = {[x0,x1,...,xd]T | x0=1, x1 ∈ ℝ,..., xd ∈ ℝ } # Create 20x3 matrix x0,x1,x2 (20 observations):\n",
    "X = np.matrix([np.asarray([1]*20),np.random.sample(size=20)*10,np.random.sample(size=20)*10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is supervised learning, each record needs an associated 'answer' or target which will let the\n",
    "# Perceptron know what the correct solution is for each record. This essentially 'guides' the machine to\n",
    "# infer a kind of framework to recreate the targets that are given and make new solutions or predictions from\n",
    "# new unseen data records.  Colors are assigned for your viewing.  I arbitrarily have chosen a formula to assign\n",
    "# each record a class.  If the two features add up to at least 8, then this data record is part of class 1 (red)\n",
    "# and if the data record's features add up to a value less than 8 then this record is part of class -1 (blue)\n",
    "\n",
    "# initialize lists for targets and target color(visualization)\n",
    "targets = []\n",
    "target_colors=[]\n",
    "\n",
    "# Record lists of data points for interactive bokeh plot:\n",
    "x1_class_red  = []\n",
    "x1_class_blue = []\n",
    "x2_class_red  = []\n",
    "x2_class_blue = []\n",
    "\n",
    "# This loop sets up the true conditions/decision criteria of 'reality'\n",
    "sum_ = sum(X[1], X[2]).tolist()[0]\n",
    "for i in range(0,np.size(X[0])):\n",
    "    if sum_[i] >= 8:\n",
    "        targets.append(1)\n",
    "        target_colors.append('r')\n",
    "        x1_class_red.append(X.tolist()[1][i])\n",
    "        x2_class_red.append(X.tolist()[2][i])\n",
    "    else:\n",
    "        targets.append(-1)\n",
    "        target_colors.append('b')\n",
    "        x1_class_blue.append(X.tolist()[1][i])\n",
    "        x2_class_blue.append(X.tolist()[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row vector for weights, w0,w1,w2; w0=bias.\n",
    "# The perceptron will determine the weights w0,w1,w2 which are 'learned' from the data features and targets above.\n",
    "# The perceptron will find weights which are also called coefficients, this coefficients add WEIGHT to a feature,\n",
    "# giving it more value or less (a common simple example is house price where size of house and lot size would  \n",
    "# be given heavy weight in determining the price (target) of a house  )\n",
    "weights = np.matrix([np.random.sample(size=3)*10] )                  \n",
    "# set bias w0 to an arbitrary value of '2.5', remaining two weights are for weighting the 2 dimensions of X \n",
    "weights[0,0]=2.5\n",
    "\n",
    "#print via pandas dataframe for easy viewing of data:\n",
    "pd.DataFrame(\n",
    "    {'[w0 (bias), w1, w2]': [weights.tolist()[0] for i in range(20)],\n",
    "     'x0': X.tolist()[0],\n",
    "     'x1': X.tolist()[1],\n",
    "     'x2': X.tolist()[2]\n",
    "    }\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  0.5620819473090188  3.0556852947698374  -1\n",
      "1.0  2.2348911141354044  7.210928266159002  1\n",
      "1.0  2.9865841443181695  5.788175305148959  1\n",
      "1.0  2.9224538768414074  0.7027898564705448  -1\n",
      "1.0  9.613455502720107  1.4507082884630929  1\n",
      "1.0  5.601800229642561  7.345988098283458  1\n",
      "1.0  7.3358053277167725  4.680105687689138  1\n",
      "1.0  0.05060503955581219  9.320673977874927  1\n",
      "1.0  9.526282474094941  1.279077004477952  1\n",
      "1.0  7.080775053971243  3.423277376981515  1\n",
      "1.0  3.062841786557203  5.6504381316035435  1\n",
      "1.0  7.889079044476594  7.073038943535312  1\n",
      "1.0  3.0382689979855115  3.8424921677703194  -1\n",
      "1.0  9.831534383031125  1.5633535555475897  1\n",
      "1.0  1.645720055129768  0.00516391235963809  -1\n",
      "1.0  3.402713439739146  2.5807036281931284  -1\n",
      "1.0  3.956793828546117  2.7111483755494206  -1\n",
      "1.0  6.4122934289500595  7.562618030280729  1\n",
      "1.0  3.834958894263214  4.677074135989824  1\n",
      "1.0  5.56044509839638  3.431007401359488  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,np.size(X[0])):\n",
    "    print(str(X[0,i])+\"  \"+ str(X[1,i]) +\"  \"+ str(X[2,i]) +\"  \" + str(targets[i]))\n",
    "    plt.scatter(\n",
    "        X[1].tolist()[0],\n",
    "        X[2].tolist()[0],\n",
    "        c=target_colors\n",
    "    );\n",
    "# Can you SEE in the plotted graph that the 2 classes of data are linearly separable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights(X,weights,targets,i):\n",
    "    new_weights = weights\n",
    "    for j in range(0,np.size(weights)):\n",
    "        new_weights[0,j] = weights[0,j] + targets[i]*X[j,i]\n",
    "    return new_weights\n",
    "\n",
    "\n",
    "def predict(X,weights, targets,x_coord_hist,y_coord_hist):\n",
    "    # Use current weights as 'hypothesis' and predict\n",
    "    predictions = []\n",
    "    prediction  = 0\n",
    "    #predict for each element in data set:\n",
    "    for i in range(0,np.size(X[0])):\n",
    "        prediction = np.dot(weights,X.T[i].T) \n",
    "        if prediction >= 0: # decision boundary is at zero \n",
    "            predictions.append(1) # if non-negative, predict class 1 or red based off current hypothesis\n",
    "            if targets[i] != 1:\n",
    "                weights = adjust_weights(X,weights,targets,i)\n",
    "        else:\n",
    "            predictions.append(-1)    # else, class -1 or blue\n",
    "            if targets[i] != -1:\n",
    "                weights = adjust_weights(X,weights,targets,i)\n",
    "                \n",
    "    # Graph after each epoch\n",
    "    x_coord_hist,y_coord_hist=graph(weights,X,x_coord_hist,y_coord_hist)    \n",
    "                \n",
    "    return predictions, weights, x_coord_hist,y_coord_hist\n",
    "\n",
    "\n",
    "def graph(weights,X, x_coord_hist,y_coord_hist):\n",
    "    w0, w1, w2 = weights[0,0],weights[0,1],weights[0,2]\n",
    "    # set x2 or 'y' to zero to find x1 or 'x' :\n",
    "    # w0x0 + w1x1 + w2x2 = 0\n",
    "    # w0x0 = b , (the bias) ->  b + w1x1 + w2x2 = 0\n",
    "    # b + w1x1 + w2x2 = 0\n",
    "    # w1x1 + w2(0) = -b\n",
    "    # w1x1 + 0 = -b\n",
    "    # x1 = -b / w1\n",
    "    x1 = (-w0) / w1\n",
    "    #set x2 or 'y' to zero to find x1 or 'x'\n",
    "    x2 = (-w0) / w2\n",
    "    # find slope and y-intercept of this 2-dimensional visualization\n",
    "    # y= mx + b\n",
    "    # 1. x=0 :     y = m(0) + b, so b = y  (0,b) \n",
    "    # 2. y=0 :     0 = m(x) + b, so m = -b / x\n",
    "    # for this program : the feature along horizontal axis is x1, so x1 = x\n",
    "    # for this program : the feature along vertical   axis is x2, so x2 = b\n",
    "    # b = x2 and m = -x2 / x1\n",
    "    b = x2\n",
    "    m = -x2 / x1\n",
    "    x_coords = np.array([0,x1])\n",
    "    y_coords = m * x_coords + b\n",
    "    #now we have two points (0,x2) and (x1,0)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-1,13])\n",
    "    axes.set_ylim([-1,13])\n",
    "    plt.clf()\n",
    "    plt.plot(x_coords, y_coords)\n",
    "    x_coord_hist.append(x_coords[1])\n",
    "    y_coord_hist.append(y_coords[0])\n",
    "    plt.scatter(\n",
    "        X[1].tolist()[0],\n",
    "        X[2].tolist()[0],\n",
    "        c=target_colors\n",
    "    )\n",
    "    # pause so humans can see some of the process\n",
    "    plt.show()\n",
    "    plt.pause(.1)\n",
    "    return x_coord_hist,y_coord_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# track number of learning steps\n",
    "epochs=0\n",
    "predictions=[]\n",
    "#keep track of each line for interactive bokeh plot in 'line_hist'\n",
    "x_coord_hist = []\n",
    "y_coord_hist = []\n",
    "\n",
    "# after each step or the fancy machine learning jargon 'epoch', I plot the learning process, which \n",
    "# shows how the machine is deciding to classify each class (you'll see the 'decision boundary move and \n",
    "# eventually settle between the classes (between the blue and red dots) ).\n",
    "# this decision boundary is an equation of a line.\n",
    "# The result of the program is an equation of the format (x0w0 + x1w1 + x2w2 = 0)\n",
    "# The program will create something and equation similar to reality x0(-8) + x1(1) + x2(1), which is our original\n",
    "# decision boundary, however, the machine doesn't know this and is instead, infering statistics (weights)\n",
    "# from the data.  Given more data points, in particular, data near the true boundary (line from 0,8 to 8,0), \n",
    "# the Perceptron would learn a model with a decision boundary closer to the true boundary.\n",
    "\n",
    "# Perceptron 'learning' : 1. predict 2. adjust weights and repeat untill all predicted values are equivalent\n",
    "# to the actual targets:\n",
    "while not (np.array_equal(predictions,targets)):\n",
    "    predictions, weights,x_coord_hist,y_coord_hist = predict(X,weights,targets,x_coord_hist,y_coord_hist)\n",
    "    epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's calculated weights in 12 epochs: \n",
      "w0: -25.5 \n",
      "w1: 2.162973070437361 \n",
      "w2: 4.647122885482666\n",
      "\n",
      "The resulting formula (plug in the existing points (x1,x2) to verify or use new data to classify new data):\n",
      "-25.5  + x1( 2.162973070437361 ) + x2( 4.647122885482666 )\n",
      "\n",
      "Values less than zero are below the decision boundary and are of classified as class -1 (blue) while values greater than or equal to zero are of class +1 (red)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perceptron's calculated weights in\",epochs,\"epochs: \\nw0:\",weights[0,0],\"\\nw1:\",weights[0,1],\"\\nw2:\",weights[0,2])\n",
    "print(\"\\nThe resulting formula (plug in the existing points (x1,x2) to verify or use new data to classify \\\n",
    "new data):\")\n",
    "print(weights[0,0],\" + x1(\",weights[0,1],\") + x2(\",weights[0,2],\")\")\n",
    "print(\"\\nValues less than zero are below the decision boundary and are of classified as class -1 (blue) while \\\n",
    "values greater than or equal to zero are of class +1 (red)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.layouts import row, widgetbox, column\n",
    "from bokeh.models import CustomJS, Slider\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.models.widgets import Button\n",
    "from bokeh.events import ButtonClick\n",
    "\n",
    "source_decision_boundary = ColumnDataSource(data=dict(x=[2,0], y=[0,4]))\n",
    "source_update_boundary   = ColumnDataSource(data=dict(x=x_coord_hist, y=y_coord_hist))\n",
    "source_class_red         = ColumnDataSource(data=dict(x=x1_class_red,     y=x2_class_red))\n",
    "source_class_blue        = ColumnDataSource(data=dict(x=x1_class_blue,    y=x2_class_blue))\n",
    "\n",
    "plot = figure(y_range=(-1, 13), x_range=(-1,13), plot_width=400, plot_height=400)\n",
    "plot.line('x', 'y', source=source_decision_boundary, line_width=3, line_alpha=0.6)\n",
    "plot.circle(x='x', y='y',source=source_class_red,  size=10, color=\"red\",  alpha=0.5)\n",
    "plot.circle(x='x', y='y',source=source_class_blue, size=10, color=\"blue\", alpha=0.5)\n",
    "\n",
    "callback = CustomJS(args=dict(source_db  = source_decision_boundary,\n",
    "                              source_db_update  = source_update_boundary,\n",
    "                              source_red = source_class_red,\n",
    "                              source_blue= source_class_blue\n",
    "                             ),\n",
    "                    code=\"\"\"\n",
    "                    var data = source_db.data;\n",
    "                    var data_update = source_db_update.data;\n",
    "                    var t = epoch_slider.value;\n",
    "                    var x = data['x']\n",
    "                    var y = data['y']\n",
    "                    x[0] = data_update['x'][t]\n",
    "                    y[1] = data_update['y'][t]\n",
    "                    source_db.change.emit();\n",
    "                    \"\"\")\n",
    "\n",
    "\n",
    "epoch_slider = Slider(start=0, end=epochs-1, value=0, step=1,\n",
    "                       title=\"Accelerate Epoch\", callback=callback)\n",
    "\n",
    "callback.args[\"epoch_slider\"] = epoch_slider\n",
    "layout = column(\n",
    "    plot,\n",
    "    widgetbox(epoch_slider)\n",
    ")\n",
    "\n",
    "output_file(\"Primitive_Perceptron_model.html\", title=\"'Primitive' (1960's) Perceptron model\")\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
