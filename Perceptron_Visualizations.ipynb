{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Learning Algorithm, Supervised learning method: \n",
    "### A break-down of Rosenblatt's simple, crude Perceptron in python,  with visualizations in matplotlib and Bokeh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Resources: A Simple Learning Model by Abu-Mostafa, Magdon-Ismail, Lin, Ch. 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "%matplotlib\n",
    "# to view graphing inside the cell use ''%matplotlib inline' instead of ''%matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This 'χ' stores multiple records as a matrix for the machine to learn from.  \n",
    "# Each row of the matrix is a piece of data, a record, an observation, event, etc.\n",
    "# First column are all 1's for multiplying with the bias weights\n",
    "# Second column contains feature 1 (x1) of each record\n",
    "# Third column contains feature 2 (x2) of each record\n",
    "# χ = {1} x ℝ^2 = {[x0,x1,...,xd]T | x0=1, x1 ∈ ℝ,..., xd ∈ ℝ } # Create 20x3 matrix x0,x1,x2 (20 observations):\n",
    "X = np.matrix([np.asarray([1]*20),np.random.sample(size=20)*10,np.random.sample(size=20)*10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is supervised learning, each record needs an associated 'answer' or target which will let the\n",
    "# Perceptron know what the correct solution is for each record. This essentially 'guides' the machine to\n",
    "# infer a kind of framework to recreate the targets that are given and make new solutions or predictions from\n",
    "# new unseen data records.  Colors are assigned for your viewing.  I arbitrarily have chosen a formula to assign\n",
    "# each record a class.  If the two features add up to at least 8, then this data record is part of class 1 (red)\n",
    "# and if the data record's features add up to a value less than 8 then this record is part of class -1 (blue)\n",
    "\n",
    "# initialize lists for targets and target color(visualization)\n",
    "targets = []\n",
    "target_colors=[]\n",
    "\n",
    "# Record lists of data points for interactive bokeh plot:\n",
    "x1_class_red  = []\n",
    "x1_class_blue = []\n",
    "x2_class_red  = []\n",
    "x2_class_blue = []\n",
    "\n",
    "# This loop sets up the true conditions/decision criteria of 'reality'\n",
    "sum_ = sum(X[1], X[2]).tolist()[0]\n",
    "for i in range(0,np.size(X[0])):\n",
    "    if sum_[i] >= 8:\n",
    "        targets.append(1)\n",
    "        target_colors.append('r')\n",
    "        x1_class_red.append(X.tolist()[1][i])\n",
    "        x2_class_red.append(X.tolist()[2][i])\n",
    "    else:\n",
    "        targets.append(-1)\n",
    "        target_colors.append('b')\n",
    "        x1_class_blue.append(X.tolist()[1][i])\n",
    "        x2_class_blue.append(X.tolist()[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row vector for weights, w0,w1,w2; w0=bias.\n",
    "# The perceptron will determine the weights w0,w1,w2 which are 'learned' from the data features and targets above.\n",
    "# The perceptron will find weights which are also called coefficients, this coefficients add WEIGHT to a feature,\n",
    "# giving it more value or less (a common simple example is house price where size of house and lot size would  \n",
    "# be given heavy weight in determining the price (target) of a house  )\n",
    "weights = np.matrix([np.random.sample(size=3)*10] )                  \n",
    "# set bias w0 to an arbitrary value of '2.5', remaining two weights are for weighting the 2 dimensions of X \n",
    "weights[0,0]=2.5\n",
    "\n",
    "#print via pandas dataframe for easy viewing of data:\n",
    "pd.DataFrame(\n",
    "    {'[w0 (bias), w1, w2]': [weights.tolist()[0] for i in range(20)],\n",
    "     'x0': X.tolist()[0],\n",
    "     'x1': X.tolist()[1],\n",
    "     'x2': X.tolist()[2]\n",
    "    }\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  1.913002791702505  9.98473162267954  1\n",
      "1.0  5.626597220698795  8.011360240204276  1\n",
      "1.0  1.9445233606166168  1.9658301965762748  -1\n",
      "1.0  4.986459818910354  0.9804553992221232  -1\n",
      "1.0  0.48590019060458567  3.237372282400851  -1\n",
      "1.0  3.797791704107901  5.299340749282509  1\n",
      "1.0  8.590531462847837  1.4843454133065181  1\n",
      "1.0  2.6519319533550023  0.18999160035520934  -1\n",
      "1.0  8.003198978088289  2.5504746575508697  1\n",
      "1.0  7.386994206308821  0.9289506075971155  1\n",
      "1.0  7.249296046131306  7.131244595178874  1\n",
      "1.0  5.776402969307491  4.123316850019436  1\n",
      "1.0  5.749178372647771  1.492239446173813  -1\n",
      "1.0  2.167316754797255  9.856051117513832  1\n",
      "1.0  1.1816572846018736  7.967764875779554  1\n",
      "1.0  7.165791572909839  5.962844091576772  1\n",
      "1.0  9.26237823474912  9.105485307500018  1\n",
      "1.0  1.3117471364588307  5.956723862086998  -1\n",
      "1.0  6.023537163268524  9.37646101683574  1\n",
      "1.0  9.960491330259241  7.560986691294964  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,np.size(X[0])):\n",
    "    print(str(X[0,i])+\"  \"+ str(X[1,i]) +\"  \"+ str(X[2,i]) +\"  \" + str(targets[i]))\n",
    "    plt.scatter(\n",
    "        X[1].tolist()[0],\n",
    "        X[2].tolist()[0],\n",
    "        c=target_colors\n",
    "    );\n",
    "# Can you SEE in the plotted graph that the 2 classes of data are linearly separable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,weights):\n",
    "    # Use current weights as 'hypothesis' and predict\n",
    "    predictions = []\n",
    "    prediction  = 0\n",
    "    #predict for each element in data set:\n",
    "    for i in range(0,np.size(X[0])):\n",
    "        prediction = np.dot(weights,X.T[i].T) \n",
    "        if prediction >= 0: # decision boundary is at zero \n",
    "            predictions.append(1) # if non-negative, predict class 1 or red based off current hypothesis\n",
    "        else:\n",
    "            predictions.append(-1)    # else, class -1 or blue\n",
    "    return predictions\n",
    "\n",
    "def adjust_weights(X,predictions, weights,targets):\n",
    "    new_weights = weights\n",
    "    for i in range(0, np.size(targets)):\n",
    "        if predictions[i] != targets[i]:\n",
    "            for j in range(0,np.size(weights)):\n",
    "                new_weights[0,j] = weights[0,j] + targets[i]*X[j,i]\n",
    "    return new_weights\n",
    "\n",
    "def graph(weights,X, x_coord_hist,y_coord_hist):\n",
    "    w0, w1, w2 = weights[0,0],weights[0,1],weights[0,2]\n",
    "    # set x2 or 'y' to zero to find x1 or 'x' :\n",
    "    # w0x0 + w1x1 + w2x2 = 0\n",
    "    # w0x0 = b , (the bias) ->  b + w1x1 + w2x2 = 0\n",
    "    # b + w1x1 + w2x2 = 0\n",
    "    # w1x1 + w2(0) = -b\n",
    "    # w1x1 + 0 = -b\n",
    "    # x1 = -b / w1\n",
    "    x1 = (-w0) / w1\n",
    "    #set x2 or 'y' to zero to find x1 or 'x'\n",
    "    x2 = (-w0) / w2\n",
    "    # find slope and y-intercept of this 2-dimensional visualization\n",
    "    # y= mx + b\n",
    "    # 1. x=0 :     y = m(0) + b, so b = y  (0,b) \n",
    "    # 2. b=0 :     0 = m(x) + b, so m = -b / x\n",
    "    # for this program : the feature along horizontal axis is x1, so x1 = x\n",
    "    # for this program : the feature along vertical   axis is x2, so x2 = b\n",
    "    # b = x2 and m = -x2 / x1\n",
    "    b = x2\n",
    "    m = -x2 / x1\n",
    "    x_coords = np.array([0,x1])\n",
    "    y_coords = m * x_coords + b\n",
    "    #now we have two points (0,x2) and (x1,0)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-1,13])\n",
    "    axes.set_ylim([-1,13])\n",
    "    plt.clf()\n",
    "    plt.plot(x_coords, y_coords)\n",
    "    x_coord_hist.append(x_coords[1])\n",
    "    y_coord_hist.append(y_coords[0])\n",
    "    plt.scatter(\n",
    "        X[1].tolist()[0],\n",
    "        X[2].tolist()[0],\n",
    "        c=target_colors\n",
    "    )\n",
    "    # pause so humans can see some of the process\n",
    "    plt.pause(.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# track number of learning steps\n",
    "epochs=0\n",
    "predictions=[]\n",
    "#keep track of each line for interactive bokeh plot in 'line_hist'\n",
    "x_coord_hist = []\n",
    "y_coord_hist = []\n",
    "\n",
    "# after each step or the fancy machine learning jargon 'epoch', I plot the learning process, which \n",
    "# shows how the machine is deciding to classify each class (you'll see the 'decision boundary move and \n",
    "# eventually settle between the classes (between the blue and red dots) ).\n",
    "# this decision boundary is an equation of a line.\n",
    "# The result of the program is an equation of the format (x0w0 + x1w1 + x2w2 = 0)\n",
    "# The program will create something and equation similar to reality x0(-8) + x1(1) + x2(1), which is our original\n",
    "# decision boundary, however, the machine doesn't know this and is instead, infering statistics (weights)\n",
    "# from the data.  Given more data points, in particular, data near the true boundary (line from 0,8 to 8,0), \n",
    "# the Perceptron would learn a model with a decision boundary closer to the true boundary.\n",
    "\n",
    "# Perceptron 'learning' : 1. predict 2. adjust weights and repeat untill all predicted values are equivalent\n",
    "# to the actual targets:\n",
    "while not (np.array_equal(predictions,targets)):\n",
    "    predictions = predict(X,weights)\n",
    "    adjust_weights(X,predictions, weights,targets)\n",
    "    epochs+=1\n",
    "    plt.show()\n",
    "    graph(weights,X,x_coord_hist,y_coord_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's calculated weights in 62 epochs: \n",
      "w0: -112.5 \n",
      "w1: 14.033955352694212 \n",
      "w2: 14.442091798738941\n",
      "\n",
      "The resulting formula (plug in the existing points (x1,x2) to verify or use new data to classify new data):\n",
      "-112.5  + x1( 14.033955352694212 ) + x2( 14.442091798738941 )\n",
      "\n",
      "Values less than zero are below the decision boundary and are of classified as class -1 (blue) while values greater than or equal to zero are of class +1 (red)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perceptron's calculated weights in\",epochs,\"epochs: \\nw0:\",weights[0,0],\"\\nw1:\",weights[0,1],\"\\nw2:\",weights[0,2])\n",
    "print(\"\\nThe resulting formula (plug in the existing points (x1,x2) to verify or use new data to classify \\\n",
    "new data):\")\n",
    "print(weights[0,0],\" + x1(\",weights[0,1],\") + x2(\",weights[0,2],\")\")\n",
    "print(\"\\nValues less than zero are below the decision boundary and are of classified as class -1 (blue) while \\\n",
    "values greater than or equal to zero are of class +1 (red)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.layouts import row, widgetbox\n",
    "from bokeh.models import CustomJS, Slider\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.layouts import widgetbox\n",
    "from bokeh.models.widgets import Button\n",
    "from bokeh.events import ButtonClick\n",
    "\n",
    "source_decision_boundary = ColumnDataSource(data=dict(x=[2,0], y=[0,4]))\n",
    "source_update_boundary   = ColumnDataSource(data=dict(x=x_coord_hist, y=y_coord_hist))\n",
    "source_class_red         = ColumnDataSource(data=dict(x=x1_class_red,     y=x2_class_red))\n",
    "source_class_blue        = ColumnDataSource(data=dict(x=x1_class_blue,    y=x2_class_blue))\n",
    "\n",
    "plot = figure(y_range=(-1, 13), x_range=(-1,13), plot_width=400, plot_height=400)\n",
    "plot.line('x', 'y', source=source_decision_boundary, line_width=3, line_alpha=0.6)\n",
    "plot.circle(x='x', y='y',source=source_class_red,  size=10, color=\"red\",  alpha=0.5)\n",
    "plot.circle(x='x', y='y',source=source_class_blue, size=10, color=\"blue\", alpha=0.5)\n",
    "\n",
    "callback = CustomJS(args=dict(source_db  = source_decision_boundary,\n",
    "                              source_db_update  = source_update_boundary,\n",
    "                              source_red = source_class_red,\n",
    "                              source_blue= source_class_blue\n",
    "                             ),\n",
    "                    code=\"\"\"\n",
    "                    var data = source_db.data;\n",
    "                    var data_update = source_db_update.data;\n",
    "                    var t = epoch_slider.value;\n",
    "                    var x = data['x']\n",
    "                    var y = data['y']\n",
    "                    x[0] = data_update['x'][t]\n",
    "                    y[1] = data_update['y'][t]\n",
    "                    source_db.change.emit();\n",
    "                    \"\"\")\n",
    "\n",
    "\n",
    "epoch_slider = Slider(start=0, end=epochs-1, value=0, step=1,\n",
    "                       title=\"Accelerate Epoch\", callback=callback)\n",
    "\n",
    "callback.args[\"epoch_slider\"] = epoch_slider\n",
    "layout = column(\n",
    "    plot,\n",
    "    widgetbox(epoch_slider,div)\n",
    ")\n",
    "\n",
    "output_file(\"Primitive_Perceptron_model.html\", title=\"'Primitive' (1960's) Perceptron model\")\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
